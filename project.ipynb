{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":332363,"sourceType":"modelInstanceVersion","modelInstanceId":278601,"modelId":299505}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nimport torch.nn.utils.spectral_norm as spectral_norm\nimport os\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandbpass\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:33:19.102610Z","iopub.execute_input":"2025-04-11T14:33:19.102946Z","iopub.status.idle":"2025-04-11T14:33:26.503359Z","shell.execute_reply.started":"2025-04-11T14:33:19.102899Z","shell.execute_reply":"2025-04-11T14:33:26.502371Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:33:28.047758Z","iopub.execute_input":"2025-04-11T14:33:28.048110Z","iopub.status.idle":"2025-04-11T14:33:28.091709Z","shell.execute_reply.started":"2025-04-11T14:33:28.048080Z","shell.execute_reply":"2025-04-11T14:33:28.090750Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install torch-fidelity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:33:30.875418Z","iopub.execute_input":"2025-04-11T14:33:30.875716Z","iopub.status.idle":"2025-04-11T14:33:35.256887Z","shell.execute_reply.started":"2025-04-11T14:33:30.875692Z","shell.execute_reply":"2025-04-11T14:33:35.255980Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-fidelity\n  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (11.0.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.13.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (0.20.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\nDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\nInstalling collected packages: torch-fidelity\nSuccessfully installed torch-fidelity-0.3.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"wandb.login(key=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:33:35.742395Z","iopub.execute_input":"2025-04-11T14:33:35.742724Z","iopub.status.idle":"2025-04-11T14:33:43.121556Z","shell.execute_reply.started":"2025-04-11T14:33:35.742690Z","shell.execute_reply":"2025-04-11T14:33:43.120825Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhexager\u001b[0m (\u001b[33mhexager-manipal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"class BottleneckResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample=False, upsample=False, spectral=False):\n        super(BottleneckResBlock, self).__init__()\n        mid_channels = in_channels // 4\n\n        self.learned_shortcut = (in_channels != out_channels) or downsample or upsample\n        self.downsample = downsample\n        self.upsample = upsample\n\n        def conv3x3(in_ch, out_ch):\n            conv = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n            return spectral_norm(conv) if spectral else conv\n\n        def conv1x1(in_ch, out_ch):\n            conv = nn.Conv2d(in_ch, out_ch, 1, 1, 0)\n            return spectral_norm(conv) if spectral else conv\n\n        self.conv1 = conv1x1(in_channels, mid_channels)\n        self.bn1 = nn.BatchNorm2d(mid_channels)\n        self.conv2 = conv3x3(mid_channels, mid_channels)\n        self.bn2 = nn.BatchNorm2d(mid_channels)\n        self.conv3 = conv1x1(mid_channels, out_channels)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if self.learned_shortcut:\n            self.shortcut = conv1x1(in_channels, out_channels)\n\n    def forward(self, x):\n        out = self.conv1(F.relu(self.bn1(x)))\n        if self.upsample:\n            out = F.interpolate(out, scale_factor=2)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        if self.downsample:\n            out = F.avg_pool2d(out, 2)\n\n        shortcut = self.shortcut(x)\n        if self.upsample:\n            shortcut = F.interpolate(shortcut, scale_factor=2)\n        if self.downsample:\n            shortcut = F.avg_pool2d(shortcut, 2)\n\n        return out + shortcut\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:40:48.931015Z","iopub.execute_input":"2025-04-11T14:40:48.931346Z","iopub.status.idle":"2025-04-11T14:40:48.940359Z","shell.execute_reply.started":"2025-04-11T14:40:48.931317Z","shell.execute_reply":"2025-04-11T14:40:48.939454Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class ConditionalBatchNorm2d(nn.Module):\n    def __init__(self, num_features, embedding_dim):\n        super(ConditionalBatchNorm2d, self).__init__()\n        self.bn = nn.BatchNorm2d(num_features, affine=False)\n        self.gamma = nn.Linear(embedding_dim, num_features)\n        self.beta = nn.Linear(embedding_dim, num_features)\n\n    def forward(self, x, y_embed):\n        out = self.bn(x)\n        gamma = self.gamma(y_embed).unsqueeze(2).unsqueeze(3)\n        beta = self.beta(y_embed).unsqueeze(2).unsqueeze(3)\n        out = gamma * out + beta\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:40:51.630539Z","iopub.execute_input":"2025-04-11T14:40:51.630900Z","iopub.status.idle":"2025-04-11T14:40:51.636561Z","shell.execute_reply.started":"2025-04-11T14:40:51.630868Z","shell.execute_reply":"2025-04-11T14:40:51.635796Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class ResBlockG(nn.Module):\n    def __init__(self, in_channels, out_channels, embedding_dim):\n        super(ResBlockG, self).__init__()\n        self.cbn1 = ConditionalBatchNorm2d(in_channels, embedding_dim)\n        self.cbn2 = ConditionalBatchNorm2d(out_channels, embedding_dim)\n        self.relu = nn.ReLU(inplace=False)\n        self.upsample = nn.Upsample(scale_factor=2)\n        self.conv1 = nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, 3, padding=1))\n        self.conv2 = nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Upsample(scale_factor=2),\n                nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, 1))\n            )\n        else:\n            self.shortcut = nn.Upsample(scale_factor=2)\n\n    def forward(self, x, y_embed):\n        out = self.cbn1(x, y_embed)\n        out = self.relu(out)\n        out = self.upsample(out)\n        out = self.conv1(out)\n        out = self.cbn2(out, y_embed)\n        out = self.relu(out)\n        out = self.conv2(out)\n        shortcut = self.shortcut(x)\n        return out + shortcut\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:40:54.086865Z","iopub.execute_input":"2025-04-11T14:40:54.087198Z","iopub.status.idle":"2025-04-11T14:40:54.094545Z","shell.execute_reply.started":"2025-04-11T14:40:54.087173Z","shell.execute_reply":"2025-04-11T14:40:54.093586Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class BigGANDeepLiteGenerator(nn.Module):\n    def __init__(self, latent_dim, num_classes, embedding_dim=128, ch=64):\n        super(BigGANDeepLiteGenerator, self).__init__()\n        self.latent_dim = latent_dim\n        self.num_classes = num_classes\n        self.embedding_dim = embedding_dim\n        self.init_size = 4\n        self.project = nn.Linear(latent_dim, (ch * 16) * self.init_size * self.init_size)\n        self.label_embedding = nn.Embedding(num_classes, embedding_dim)\n\n        self.resblock1 = ResBlockG(ch * 16, ch * 8, embedding_dim)\n        self.resblock2 = ResBlockG(ch * 8, ch * 4, embedding_dim)\n        self.resblock3 = ResBlockG(ch * 4, ch * 2, embedding_dim)\n\n        self.bn = nn.BatchNorm2d(ch * 2)\n        self.relu = nn.ReLU(inplace=False)\n        self.final_conv = nn.utils.spectral_norm(nn.Conv2d(ch * 2, 3, 3, padding=1))\n        self.tanh = nn.Tanh()\n\n    def forward(self, z, labels):\n        y_embed = self.label_embedding(labels)\n        out = self.project(z).view(z.size(0), -1, self.init_size, self.init_size)\n\n        out = self.resblock1(out, y_embed)\n        out = self.resblock2(out, y_embed)\n        out = self.resblock3(out, y_embed)\n\n        out = self.relu(self.bn(out))\n        out = self.final_conv(out)\n        out = self.tanh(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:40:58.120205Z","iopub.execute_input":"2025-04-11T14:40:58.120485Z","iopub.status.idle":"2025-04-11T14:40:58.128070Z","shell.execute_reply.started":"2025-04-11T14:40:58.120465Z","shell.execute_reply":"2025-04-11T14:40:58.127344Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\nclass ResBlockD(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample=True):\n        super(ResBlockD, self).__init__()\n        self.downsample = downsample\n        self.learned_shortcut = (in_channels != out_channels) or downsample\n\n        self.conv1 = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n        self.conv2 = spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n        self.activation = nn.ReLU(inplace=False)\n        self.avgpool = nn.AvgPool2d(2)\n\n        if self.learned_shortcut:\n            self.shortcut = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0))\n\n    def forward(self, x):\n        residual = x\n\n        out = self.activation(x)\n        out = self.conv1(out)\n        out = self.activation(out)\n        out = self.conv2(out)\n        if self.downsample:\n            out = self.avgpool(out)\n\n        if self.learned_shortcut:\n            residual = self.shortcut(residual)\n            if self.downsample:\n                residual = self.avgpool(residual)\n\n        return out + residual","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:41:00.442971Z","iopub.execute_input":"2025-04-11T14:41:00.443258Z","iopub.status.idle":"2025-04-11T14:41:00.450583Z","shell.execute_reply.started":"2025-04-11T14:41:00.443235Z","shell.execute_reply":"2025-04-11T14:41:00.449830Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class BigGANDeepLiteDiscriminator(nn.Module):\n    def __init__(self, num_classes=10, channels=64):\n        super(BigGANDeepLiteDiscriminator, self).__init__()\n        self.block1 = ResBlockD(3, channels, downsample=True)\n        self.block2 = ResBlockD(channels, channels * 2, downsample=True)\n        self.block3 = ResBlockD(channels * 2, channels * 4, downsample=True)\n        self.block4 = ResBlockD(channels * 4, channels * 8, downsample=True)\n        self.block5 = ResBlockD(channels * 8, channels * 16, downsample=False)\n\n        self.activation = nn.ReLU(inplace=False)\n        self.linear = spectral_norm(nn.Linear(channels * 16, 1))\n\n        # For projection discriminator (conditional)\n        self.embed = spectral_norm(nn.Embedding(num_classes, channels * 16))\n\n    def forward(self, x, y):\n        out = self.block1(x)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.block4(out)\n        out = self.block5(out)\n\n        out = self.activation(out)\n        out = torch.sum(out, dim=(2, 3))  # Global sum pooling\n\n        output = self.linear(out)\n\n        # Projection discriminator term\n        y_embed = self.embed(y)\n        proj = torch.sum(out * y_embed, dim=1, keepdim=True)\n\n        return output + proj\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:41:03.376429Z","iopub.execute_input":"2025-04-11T14:41:03.376728Z","iopub.status.idle":"2025-04-11T14:41:03.384149Z","shell.execute_reply.started":"2025-04-11T14:41:03.376705Z","shell.execute_reply":"2025-04-11T14:41:03.383322Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"data_root = '/kaggle/working/'\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\ntrain_dataset = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:39:06.729999Z","iopub.execute_input":"2025-04-11T14:39:06.730272Z","iopub.status.idle":"2025-04-11T14:39:23.140373Z","shell.execute_reply.started":"2025-04-11T14:39:06.730252Z","shell.execute_reply":"2025-04-11T14:39:23.139475Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /kaggle/working/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:11<00:00, 14.3MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/cifar-10-python.tar.gz to /kaggle/working/\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_loader = DataLoader(\n    train_dataset,\n    batch_size=64,\n    shuffle=True,\n    pin_memory=True  # Optional: can help on GPU\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:39:28.711693Z","iopub.execute_input":"2025-04-11T14:39:28.712154Z","iopub.status.idle":"2025-04-11T14:39:28.716283Z","shell.execute_reply.started":"2025-04-11T14:39:28.712113Z","shell.execute_reply":"2025-04-11T14:39:28.715338Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"run = wandb.init(\n    entity=\"Hexager-manipal\",\n    # Set the wandb project where this run will be logged.\n    project=\"Big-Gan-similar\",\n    # Track hyperparameters and run metadata.\n    config={\n        \"learning_rate\": 2e-4,\n        \"architecture\": \"BIG-GAN-deep-lite-simplified w/o enhancements\",\n        \"dataset\": \"CIFAR-10\",\n        \"epochs\": 20\n    },\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:39:33.429665Z","iopub.execute_input":"2025-04-11T14:39:33.430010Z","iopub.status.idle":"2025-04-11T14:39:40.304480Z","shell.execute_reply.started":"2025-04-11T14:39:33.429980Z","shell.execute_reply":"2025-04-11T14:39:40.303834Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhexager\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250411_143933-6av3m0su</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hexager-manipal/Big-Gan-similar/runs/6av3m0su' target=\"_blank\">still-pond-2</a></strong> to <a href='https://wandb.ai/hexager-manipal/Big-Gan-similar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hexager-manipal/Big-Gan-similar' target=\"_blank\">https://wandb.ai/hexager-manipal/Big-Gan-similar</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hexager-manipal/Big-Gan-similar/runs/6av3m0su' target=\"_blank\">https://wandb.ai/hexager-manipal/Big-Gan-similar/runs/6av3m0su</a>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:39:51.522006Z","iopub.execute_input":"2025-04-11T14:39:51.522305Z","iopub.status.idle":"2025-04-11T14:39:51.526685Z","shell.execute_reply.started":"2025-04-11T14:39:51.522283Z","shell.execute_reply":"2025-04-11T14:39:51.525901Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def save_checkpoint(generator, discriminator, g_optimizer, d_optimizer,\n                    epoch, step,  path=\"checkpoints\", filename=\"last.pth\"):\n    os.makedirs(path, exist_ok=True)\n    \n    checkpoint = {\n        \"generator\": generator.state_dict(),\n        \"discriminator\": discriminator.state_dict(),\n        \"g_optimizer\": g_optimizer.state_dict(),\n        \"d_optimizer\": d_optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"step\": step,\n        #\"best_fid\": best_fid,\n    }\n    \n    torch.save(checkpoint, os.path.join(path, filename))\n    #if is_best:\n        #torch.save(checkpoint, os.path.join(path, \"best.pth\"))\n\n\ndef load_checkpoint(generator, discriminator, g_optimizer, d_optimizer, path=\"checkpoints/last.pth\"):\n    checkpoint = torch.load(path)\n    generator.load_state_dict(checkpoint[\"generator\"])\n    discriminator.load_state_dict(checkpoint[\"discriminator\"])\n    g_optimizer.load_state_dict(checkpoint[\"g_optimizer\"])\n    d_optimizer.load_state_dict(checkpoint[\"d_optimizer\"])\n    return checkpoint[\"epoch\"], checkpoint[\"step\"] #checkpoint[\"best_fid\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:39:54.154688Z","iopub.execute_input":"2025-04-11T14:39:54.154993Z","iopub.status.idle":"2025-04-11T14:39:54.161055Z","shell.execute_reply.started":"2025-04-11T14:39:54.154969Z","shell.execute_reply":"2025-04-11T14:39:54.160229Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torchvision.utils import make_grid, save_image\nfrom tqdm import tqdm\n\ndef hinge_discriminator_loss(D_real, D_fake):\n    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n\ndef hinge_generator_loss(D_fake):\n    return -torch.mean(D_fake)\n\ndef sample_latent(batch_size, z_dim, num_classes, device):\n    z = torch.randn(batch_size, z_dim, device=device)\n    y = torch.randint(0, num_classes, (batch_size,), device=device)\n    return z, y\n\ndef train(generator, discriminator, dataloader, num_classes, z_dim=128, \n          epochs=100, lr_g=2e-4, lr_d=2e-4, device='cuda', \n          g_steps=1, d_steps=1, save_interval=5):\n    log_interval = 2\n    generator = generator.to(device)\n    discriminator = discriminator.to(device)\n\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(0.0, 0.999))\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.0, 0.999))\n\n    step = 0\n\n    for epoch in range(epochs):\n        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for real_imgs, labels in pbar:\n            real_imgs, labels = real_imgs.to(device), labels.to(device)\n            batch_size = real_imgs.size(0)\n            # Train Discriminator\n            \n            for _ in range(d_steps):\n                z, y = sample_latent(batch_size, z_dim, num_classes, device)\n                fake_imgs = generator(z, y).detach()\n                \n                D_real = discriminator(real_imgs, labels)\n                D_fake = discriminator(fake_imgs, y)\n\n                loss_d = hinge_discriminator_loss(D_real, D_fake)\n\n                opt_d.zero_grad()\n                loss_d.backward()\n                opt_d.step()\n                \n            # Train Generator\n            \n            for _ in range(g_steps):\n                z, y = sample_latent(batch_size, z_dim, num_classes, device)\n                fake_imgs = generator(z, y)\n                D_fake = discriminator(fake_imgs, y)\n\n                loss_g = hinge_generator_loss(D_fake)\n\n                opt_g.zero_grad()\n                loss_g.backward()\n                opt_g.step()\n\n            pbar.set_postfix({\"loss_d\": loss_d.item(), \"loss_g\": loss_g.item()})\n            step += 1\n            if step % log_interval == 0:\n                wandb.log({\n                    \"g_loss\": loss_g.item(),\n                    \"d_loss\": loss_d.item(),\n                })\n\n        save_checkpoint(generator, discriminator, opt_g, opt_d, epoch, step)\n        # ------------------\n        # Save Images\n        # ------------------\n        if epoch % 5 == 0:\n            generator.eval()\n            with torch.no_grad():\n                n_classes = num_classes\n                samples_per_class = 8\n                fixed_labels = torch.arange(n_classes, device=device).repeat_interleave(samples_per_class)\n                fixed_z = torch.randn(n_classes * samples_per_class, z_dim, device=device)\n        \n                fakes = generator(fixed_z, fixed_labels)\n                grid = torchvision.utils.make_grid(fakes, nrow=samples_per_class, normalize=True, pad_value=1)\n        \n                wandb.log({\n                    \"Class-conditional Samples\": [wandb.Image(grid, caption=f\"Epoch {epoch} - One row per class\")]\n                })\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:41:24.880348Z","iopub.execute_input":"2025-04-11T14:41:24.880677Z","iopub.status.idle":"2025-04-11T14:41:24.892675Z","shell.execute_reply.started":"2025-04-11T14:41:24.880647Z","shell.execute_reply":"2025-04-11T14:41:24.892010Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"generator = BigGANDeepLiteGenerator(latent_dim=128, num_classes=10)\ndiscriminator = BigGANDeepLiteDiscriminator(num_classes=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:38:27.112127Z","iopub.execute_input":"2025-04-11T15:38:27.112465Z","iopub.status.idle":"2025-04-11T15:38:27.338666Z","shell.execute_reply.started":"2025-04-11T15:38:27.112435Z","shell.execute_reply":"2025-04-11T15:38:27.337999Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train(\n    generator=generator,\n    discriminator=discriminator,\n    dataloader=train_loader,\n    num_classes=10,\n    z_dim=128,\n    epochs=20,\n    lr_g=2e-4,\n    lr_d=2e-4,\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    g_steps=1,\n    d_steps=1,\n    save_interval=5\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T14:41:30.448285Z","iopub.execute_input":"2025-04-11T14:41:30.448598Z","iopub.status.idle":"2025-04-11T15:28:48.588498Z","shell.execute_reply.started":"2025-04-11T14:41:30.448569Z","shell.execute_reply":"2025-04-11T15:28:48.587500Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.07, loss_g=0.105]   \nEpoch 2/20: 100%|██████████| 782/782 [02:21<00:00,  5.53it/s, loss_d=2.07, loss_g=-0.0128]  \nEpoch 3/20: 100%|██████████| 782/782 [02:21<00:00,  5.53it/s, loss_d=1.94, loss_g=-0.0466] \nEpoch 4/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.05, loss_g=0.187]    \nEpoch 5/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.15, loss_g=0.00628] \nEpoch 6/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.01, loss_g=0.109]    \nEpoch 7/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.08, loss_g=0.0342]   \nEpoch 8/20: 100%|██████████| 782/782 [02:21<00:00,  5.53it/s, loss_d=1.92, loss_g=0.00907]  \nEpoch 9/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2, loss_g=-0.0451]     \nEpoch 10/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=2.08, loss_g=0.0433]   \nEpoch 11/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=1.91, loss_g=-0.0105] \nEpoch 12/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=2.04, loss_g=-0.352] \nEpoch 13/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=2, loss_g=-0.35]     \nEpoch 14/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=2, loss_g=-0.164]   \nEpoch 15/20: 100%|██████████| 782/782 [02:20<00:00,  5.56it/s, loss_d=2.07, loss_g=-0.121]  \nEpoch 16/20: 100%|██████████| 782/782 [02:20<00:00,  5.55it/s, loss_d=1.86, loss_g=-0.106]  \nEpoch 17/20: 100%|██████████| 782/782 [02:21<00:00,  5.53it/s, loss_d=2.03, loss_g=-0.0406]  \nEpoch 18/20: 100%|██████████| 782/782 [02:21<00:00,  5.53it/s, loss_d=1.98, loss_g=-0.0678]  \nEpoch 19/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.08, loss_g=-0.0375]  \nEpoch 20/20: 100%|██████████| 782/782 [02:21<00:00,  5.54it/s, loss_d=2.07, loss_g=-0.0619]  \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:29:40.462540Z","iopub.execute_input":"2025-04-11T15:29:40.462826Z","iopub.status.idle":"2025-04-11T15:29:43.601273Z","shell.execute_reply.started":"2025-04-11T15:29:40.462802Z","shell.execute_reply":"2025-04-11T15:29:43.600457Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>▁█▅▆▆▆▇▇▆▆▆▇▆▆▅▇▆▇▆▇▆▇▆▆▂▆▅▆▆▆▇▆▇▆▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>g_loss</td><td>▄▅▅▅▅▆▅▅▅▅▅▆▅▆▅▅█▃▂▃▁▁▃▃▃▃▃▃▃▅▄▄▄▄▄▄▅▅▅▅</td></tr><tr><td>step</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>2.0707</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>g_loss</td><td>-0.06188</td></tr><tr><td>step</td><td>15640</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">still-pond-2</strong> at: <a href='https://wandb.ai/hexager-manipal/Big-Gan-similar/runs/6av3m0su' target=\"_blank\">https://wandb.ai/hexager-manipal/Big-Gan-similar/runs/6av3m0su</a><br> View project at: <a href='https://wandb.ai/hexager-manipal/Big-Gan-similar' target=\"_blank\">https://wandb.ai/hexager-manipal/Big-Gan-similar</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 4 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250411_143933-6av3m0su/logs</code>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:42:13.820390Z","iopub.execute_input":"2025-04-11T17:42:13.820719Z","iopub.status.idle":"2025-04-11T17:42:14.682608Z","shell.execute_reply.started":"2025-04-11T17:42:13.820694Z","shell.execute_reply":"2025-04-11T17:42:14.681930Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"generator = BigGANDeepLiteGenerator(latent_dim=128, num_classes=10)\ngenerator.load_state_dict(torch.load(\"/kaggle/working/checkpoints/last.pth\")[\"generator\"])\ngenerator.cpu()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:42:27.493458Z","iopub.execute_input":"2025-04-11T17:42:27.493778Z","iopub.status.idle":"2025-04-11T17:42:27.971766Z","shell.execute_reply.started":"2025-04-11T17:42:27.493750Z","shell.execute_reply":"2025-04-11T17:42:27.970887Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-69-a8f5f1e42102>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  generator.load_state_dict(torch.load(\"/kaggle/working/checkpoints/last.pth\")[\"generator\"])\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"BigGANDeepLiteGenerator(\n  (project): Linear(in_features=128, out_features=16384, bias=True)\n  (label_embedding): Embedding(10, 128)\n  (resblock1): ResBlockG(\n    (cbn1): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=1024, bias=True)\n      (beta): Linear(in_features=128, out_features=1024, bias=True)\n    )\n    (cbn2): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=512, bias=True)\n      (beta): Linear(in_features=128, out_features=512, bias=True)\n    )\n    (relu): ReLU()\n    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (shortcut): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (resblock2): ResBlockG(\n    (cbn1): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=512, bias=True)\n      (beta): Linear(in_features=128, out_features=512, bias=True)\n    )\n    (cbn2): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=256, bias=True)\n      (beta): Linear(in_features=128, out_features=256, bias=True)\n    )\n    (relu): ReLU()\n    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (shortcut): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (resblock3): ResBlockG(\n    (cbn1): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=256, bias=True)\n      (beta): Linear(in_features=128, out_features=256, bias=True)\n    )\n    (cbn2): ConditionalBatchNorm2d(\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n      (gamma): Linear(in_features=128, out_features=128, bias=True)\n      (beta): Linear(in_features=128, out_features=128, bias=True)\n    )\n    (relu): ReLU()\n    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (shortcut): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU()\n  (final_conv): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (tanh): Tanh()\n)"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom scipy.linalg import sqrtm\nfrom tqdm.notebook import tqdm\nfrom torchvision.models import inception_v3, Inception_V3_Weights\n\n# Set device\ndevice = torch.device(\"cpu\")\n\n# Load pre-trained InceptionV3 model (for classification logits)\nfrom torchvision.models import inception_v3\nweights = Inception_V3_Weights.DEFAULT\ninception_model = inception_v3(weights=weights, aux_logits=True).to(device)\ninception_model.eval()\n\n# Function to extract features\ndef get_inception_features(images, model):\n    if model is None:\n        return None\n    up = torch.nn.Upsample(size=(299, 299), mode='bilinear', align_corners=False).to(device)\n\n    def get_pred(x):\n        if next(model.parameters()).device != x.device:\n            x = x.to(next(model.parameters()).device)\n        x = up(x)\n        return model(x)\n\n    features = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(images), 64)):\n            batch = images[i:i + 32].to(device)\n            pred = get_pred(batch)\n            if pred is not None:\n                features.append(pred.cpu().numpy())\n    return np.concatenate(features, axis=0)\n\n# FID calculation function\ndef calculate_fid(real_features, fake_features):\n    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n    mu2, sigma2 = fake_features.mean(axis=0), np.cov(fake_features, rowvar=False)\n    ssdiff = np.sum((mu1 - mu2)**2.0)\n    try:\n        covmean = sqrtm(sigma1.dot(sigma2))\n    except Exception as e:\n        print(f\"Error calculating covariance mean: {e}\")\n        return np.nan\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid\n\n# Parameters for fake data\nnum_fake_images = 5000\nlatent_dim = 128\nnum_classes = 10  # For CIFAR-10\n\n# Generate fake images using your generator\ngenerator.to(device)\nfixed_noise = torch.randn(num_fake_images, latent_dim).to(device)\nfixed_labels = torch.randint(0, num_classes, (num_fake_images,)).to(device)\n\nwith torch.no_grad():\n    generated_images = generator(fixed_noise, fixed_labels).detach().cpu()\n    generated_images = (generated_images * 0.5 + 0.5).clamp(0, 1)  # Scale to [0,1]\n\n# Load real CIFAR-10 images\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\nreal_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n# Get a subset of real images (same size as fake)\nindices = np.random.choice(len(real_dataset), num_fake_images, replace=False)\nreal_images_subset = [real_dataset[i][0] for i in indices]\nreal_images_tensor = torch.stack(real_images_subset)\nreal_images_tensor = (real_images_tensor * 0.5 + 0.5).clamp(0, 1)  # Denormalize to [0,1]\n\n# Extract features\nprint(\"Calculating Inception features for real images...\")\nreal_features = get_inception_features(real_images_tensor.to(device), inception_model)\n\nprint(\"Calculating Inception features for fake images...\")\nfake_features = get_inception_features(generated_images.to(device), inception_model)\n\n# Compute FID\nif real_features is not None and fake_features is not None:\n    fid_score = calculate_fid(real_features, fake_features)\n    print(f\"FID Score: {fid_score:.4f}\")\nelse:\n    print(\"Could not calculate FID score due to an issue with the Inception model.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:58:34.371530Z","iopub.execute_input":"2025-04-11T16:58:34.371810Z","iopub.status.idle":"2025-04-11T17:12:17.189031Z","shell.execute_reply.started":"2025-04-11T16:58:34.371789Z","shell.execute_reply":"2025-04-11T17:12:17.188107Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:11<00:00, 14.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nCalculating Inception features for real images...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869ba50f1fea45a5bf522919087db38e"}},"metadata":{}},{"name":"stdout","text":"Calculating Inception features for fake images...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c161ef15e842918ca86ab6f616fadf"}},"metadata":{}},{"name":"stdout","text":"FID Score: 231.8393\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from torchvision.datasets import CIFAR10\nfrom torchvision import transforms\nimport torch\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),                   # [0,1]\n    transforms.Normalize((0.5, 0.5, 0.5),     # back to [-1, 1]\n                         (0.5, 0.5, 0.5))\n])\n\nreal_dataset = CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\nreal_images = torch.stack([real_dataset[i][0] for i in range(5000)])  # shape: [5000, 3, 32, 32]\ngenerator.eval().to(\"cuda\")\nlatent_dim = 128\nnum_classes = 10\nbatch_size = 64\nfakes = []\n\nwith torch.no_grad():\n    for _ in range(5000 // batch_size):\n        z = torch.randn(batch_size, latent_dim).to(\"cuda\")\n        y = torch.randint(0, num_classes, (batch_size,), device=\"cuda\")\n        out = generator(z, y)\n        fakes.append(out.cpu())  # offload to CPU to save VRAM\n\nfakes_tensor = torch.cat(fakes, dim=0)  # [5000, 3, 32, 32]\n\ndef denorm(x):\n    return (x * 0.5 + 0.5).clamp(0, 1)\n\nreal_images = denorm(real_images)\nfakes_tensor = denorm(fakes_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:45:43.297849Z","iopub.execute_input":"2025-04-11T17:45:43.298192Z","iopub.status.idle":"2025-04-11T17:45:46.883900Z","shell.execute_reply.started":"2025-04-11T17:45:43.298167Z","shell.execute_reply":"2025-04-11T17:45:46.883168Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from torchmetrics.image.fid import FrechetInceptionDistance\n\nfid = FrechetInceptionDistance(feature=2048, normalize=True).to(\"cuda\")\n\n# Feed real images\nfor i in range(0, 5000, batch_size):\n    real_batch = real_images[i:i+batch_size].to(\"cuda\")\n    fid.update(real_batch, real=True)\n\n# Feed fake images\nfor i in range(0, fakes_tensor.size(0), batch_size):\n    fake_batch = fakes_tensor[i:i+batch_size]\n    if fake_batch.size(0) == 0:\n        continue  # skip empty batches just in case\n    fid.update(fake_batch.to(\"cuda\"), real=False)\n\n\n# Compute score\nscore = fid.compute().item()\nprint(f\"✅ Final FID Score: {score:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:47:34.727934Z","iopub.execute_input":"2025-04-11T17:47:34.728344Z","iopub.status.idle":"2025-04-11T17:47:59.368737Z","shell.execute_reply.started":"2025-04-11T17:47:34.728311Z","shell.execute_reply":"2025-04-11T17:47:59.367924Z"}},"outputs":[{"name":"stdout","text":"✅ Final FID Score: 122.45\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"from torchmetrics.image.inception import InceptionScore\n\n# Normalize fake images to [0, 1] if not already\nfake_imgs = fakes_tensor.clone()  # shape: [5000, 3, 32, 32]\nfake_imgs = fake_imgs.clamp(0, 1)\n\n# Create IS object\nis_metric = InceptionScore(normalize=True, splits=10).to(\"cuda\")\n\n# Feed fake images in batches\nbatch_size = 64\nfor i in range(0, fake_imgs.size(0), batch_size):\n    batch = fake_imgs[i:i+batch_size]\n    if batch.size(0) == 0:\n        continue\n    is_metric.update(batch.to(\"cuda\"))\n\n# Compute IS\nscore, std = is_metric.compute()\nprint(f\"✅ Inception Score: {score:.2f} ± {std:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:49:02.529675Z","iopub.execute_input":"2025-04-11T17:49:02.530010Z","iopub.status.idle":"2025-04-11T17:49:13.397192Z","shell.execute_reply.started":"2025-04-11T17:49:02.529983Z","shell.execute_reply":"2025-04-11T17:49:13.396201Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n  warnings.warn(*args, **kwargs)  # noqa: B028\n","output_type":"stream"},{"name":"stdout","text":"✅ Inception Score: 4.04 ± 0.16\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"generator.eval().to(\"cuda\")\nlatent_dim = 128\nnum_classes = 10\nbatch_size = 64\nfakes = []\n\nwith torch.no_grad():\n    for _ in range(5000 // batch_size):\n        z = torch.randn(batch_size, latent_dim).to(\"cuda\")\n        y = torch.randint(0, num_classes, (batch_size,), device=\"cuda\")\n        out = generator(z, y)\n        fakes.append(out.cpu())  # offload to CPU to save VRAM\n\nfakes_tensor = torch.cat(fakes, dim=0)  # [5000, 3, 32, 32]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom scipy.linalg import sqrtm\nfrom tqdm.notebook import tqdm\nfrom torchvision.models import inception_v3, Inception_V3_Weights\nimport torch.nn.functional as F\n\n# Set device\ndevice = torch.device(\"cpu\")\n\n# Load pre-trained InceptionV3 model (for classification logits)\nfrom torchvision.models import inception_v3\nweights = Inception_V3_Weights.DEFAULT\ninception_model = inception_v3(weights=weights, aux_logits=False).to(device) # Set aux_logits to False for final layer output\ninception_model.eval()\n\n# Function to extract features (logits for IS)\ndef get_inception_logits(images, model):\n    if model is None:\n        return None\n    up = torch.nn.Upsample(size=(299, 299), mode='bilinear', align_corners=False).to(device)\n\n    def get_pred(x):\n        if next(model.parameters()).device != x.device:\n            x = x.to(next(model.parameters()).device)\n        x = up(x)\n        return model(x)\n\n    logits = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(images), 64)):\n            batch = images[i:i + 32].to(device)\n            pred = get_pred(batch)\n            if pred is not None:\n                logits.append(pred.cpu().numpy())\n    return np.concatenate(logits, axis=0)\n\n# Inception Score calculation function\ndef calculate_is(logits):\n    probs = F.softmax(torch.from_numpy(logits), dim=1).numpy()\n    p_y = np.mean(probs, axis=0)\n    scores = []\n    for i in range(probs.shape[0]):\n        scores.append(np.sum(probs[i] * np.log(probs[i] / p_y)))\n    mean_score = np.mean(scores)\n    std_score = np.std(scores)\n    return np.exp(mean_score), np.exp(std_score)\n\n# Parameters for fake data\nnum_fake_images = 5000\nlatent_dim = 128\nnum_classes = 10  # For CIFAR-10 (assuming your generator is for CIFAR-10 or similar)\n\n# Assuming your generator is already defined and accessible as 'generator'\n# and it takes 'fixed_noise' and 'fixed_labels' as input if it's a conditional generator\n\n# Generate fake images using your generator\ngenerator.to(device)\nfixed_noise = torch.randn(num_fake_images, latent_dim).to(device)\nfixed_labels = torch.randint(0, num_classes, (num_fake_images,)).to(device)\n\nwith torch.no_grad():\n    generated_images = generator(fixed_noise, fixed_labels).detach().cpu()\n    generated_images = (generated_images + 1) / 2.0 # Scale to [0,1] if generator outputs [-1, 1]. Adjust as needed.\n\n# Extract Inception logits for fake images\nprint(\"Calculating Inception logits for fake images...\")\nfake_logits = get_inception_logits(generated_images.to(device), inception_model)\n\n# Compute Inception Score\nif fake_logits is not None:\n    mean_is, std_is = calculate_is(fake_logits)\n    print(f\"Inception Score for fake images: {mean_is:.4f} +/- {std_is:.4f}\")\nelse:\n    print(\"Could not calculate Inception Score due to an issue with the Inception model.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install clean-fid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:30:41.902890Z","iopub.execute_input":"2025-04-11T17:30:41.903243Z","iopub.status.idle":"2025-04-11T17:30:45.721654Z","shell.execute_reply.started":"2025-04-11T17:30:41.903215Z","shell.execute_reply":"2025-04-11T17:30:45.720751Z"}},"outputs":[{"name":"stdout","text":"Collecting clean-fid\n  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clean-fid) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clean-fid) (0.20.1+cu121)\nRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (1.26.4)\nRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (1.13.1)\nRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (4.67.1)\nRequirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid) (11.0.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from clean-fid) (2.32.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->clean-fid) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clean-fid) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clean-fid) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clean-fid) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.3->clean-fid) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.3->clean-fid) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.3->clean-fid) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.3->clean-fid) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.3->clean-fid) (2024.2.0)\nDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\nInstalling collected packages: clean-fid\nSuccessfully installed clean-fid-0.1.35\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"from cleanfid import fid\nfid_score = fid.compute_fid(\"output_fake\", dataset_name=\"cifar10\", dataset_split=\"test\")\nprint(\"CleanFID Score:\", fid_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:34:32.567323Z","iopub.execute_input":"2025-04-11T17:34:32.567726Z","iopub.status.idle":"2025-04-11T17:34:33.573165Z","shell.execute_reply.started":"2025-04-11T17:34:32.567698Z","shell.execute_reply":"2025-04-11T17:34:33.571964Z"}},"outputs":[{"name":"stdout","text":"compute FID of a folder with cifar10 statistics\ndownloading statistics to /usr/local/lib/python3.10/dist-packages/cleanfid/stats/cifar10_clean_test_1024.npz\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-c8f918495dcf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcleanfid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_fake\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cifar10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CleanFID Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfid_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/fid.py\u001b[0m in \u001b[0;36mcompute_fid\u001b[0;34m(fdir1, fdir2, gen, mode, model_name, num_workers, batch_size, device, dataset_name, dataset_res, dataset_split, num_gen, z_dim, custom_feat_extractor, verbose, custom_image_tranform, custom_fn_resize, use_dataparallel)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"compute FID of a folder with {dataset_name} statistics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         score = fid_folder(fdir1, dataset_name, dataset_res, dataset_split,\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mcustom_fn_resize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_fn_resize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_image_tranform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_image_tranform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/fid.py\u001b[0m in \u001b[0;36mfid_folder\u001b[0;34m(fdir, dataset_name, dataset_res, dataset_split, model, mode, model_name, num_workers, batch_size, device, verbose, custom_image_tranform, custom_fn_resize)\u001b[0m\n\u001b[1;32m    171\u001b[0m                custom_image_tranform=None, custom_fn_resize=None):\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# Load reference FID statistics (download if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     ref_mu, ref_sigma = get_reference_statistics(dataset_name, dataset_res,\n\u001b[0m\u001b[1;32m    174\u001b[0m                             mode=mode, model_name=model_name, seed=0, split=dataset_split)\n\u001b[1;32m    175\u001b[0m     \u001b[0mfbname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/features.py\u001b[0m in \u001b[0;36mget_reference_statistics\u001b[0;34m(name, res, mode, model_name, seed, split, metric)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mstats_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stats\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_download_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sigma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/downloads_helper.py\u001b[0m in \u001b[0;36mcheck_download_url\u001b[0;34m(local_folder, url)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"downloading statistics to {local_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"],"ename":"HTTPError","evalue":"HTTP Error 404: Not Found","output_type":"error"}],"execution_count":66}]}